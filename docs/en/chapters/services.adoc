=== Namespaces ===

Create the necessary namespaces :

----
$ kubectl apply -f k8s/namespaces/ --record

$ kubectl get ns -l provider=jarvis
NAME             STATUS    AGE
hypriot          Active    14d
ingress-system   Active    14d
logs             Active    14d
metrics          Active    14d
monitoring       Active    14d
security         Active    49m
tools            Active    14d
----

=== Storage ===

We use a NFS server for storage. So we will use the NFS client provisionner :

----
$ kubectl apply -f k8s/nfs-client-provisioner/
----

After that, creates a POD to check the NFS access :

----
$ kubectl create -f k8s/nfs-client-provisioner/nfs-pvc-test.yaml
$ kubectl create -f k8s/nfs-client-provisioner/nfs-pod-test.yaml
$ kubectl get pods
NAME                                      READY     STATUS              RESTARTS   AGE
hypriot-2682716425-bldnh                  1/1       Running             0          28d
nfs-client-provisioner-3721834868-6phzj   1/1       Running             0          1h
test-pod                                  0/1       ContainerCreating   0          4s

$ kubectl describe pod test-pod
Name:           test-pod
Namespace:      default
Node:           jarvis-node2/192.168.1.26
Start Time:     Sat, 23 Sep 2017 13:28:09 +0200
Labels:         <none>
Annotations:    <none>
Status:         Succeeded
IP:             10.36.0.2
Containers:
  test-pod:
    Container ID:       docker://351a925cad33164929975010fc128f5a2590f7d941849170caef0ffa6f56ef7c
    Image:              hypriot/armhf-busybox:1.24
    Image ID:           docker-pullable://hypriot/armhf-busybox@sha256:746423cb45f66db032f2138f7459a26051dadb1c5101727bd8abb847c6f90b7f
    Port:               <none>
    Command:
      /bin/sh
    Args:
      -c
      touch /mnt/SUCCESS && exit 0 || exit 1
    State:              Terminated
      Reason:           Completed
      Exit Code:        0
      Started:          Sat, 23 Sep 2017 13:28:19 +0200
      Finished:         Sat, 23 Sep 2017 13:28:19 +0200
    Ready:              False
    Restart Count:      0
    Environment:        <none>
    Mounts:
      /mnt from nfs-pvc (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5chdh (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         False
  PodScheduled  True
Volumes:
  nfs-pvc:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  test-claim
    ReadOnly:   false
  default-token-5chdh:
    Type:       Secret (a volume populated by a Secret)
    SecretName: default-token-5chdh
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: <none>
Tolerations:    node.alpha.kubernetes.io/notReady:NoExecute for 300s
                node.alpha.kubernetes.io/unreachable:NoExecute for 300s
vents:
  FirstSeen     LastSeen        Count   From                    SubObjectPath                   Type            Reason                  Message
  ---------     --------        -----   ----                    -------------                   --------        ------                  -------
  14s           14s             1       default-scheduler                                       Normal          Scheduled               Successfully assigned t
est-pod to jarvis-node2
  14s           14s             1       kubelet, jarvis-node2                                   Normal          SuccessfulMountVolume   MountVolume.SetUp succe
eded for volume "default-token-5chdh"
  14s           14s             1       kubelet, jarvis-node2                                   Normal          SuccessfulMountVolume   MountVolume.SetUp succe
eded for volume "pvc-26194824-a052-11e7-9c1e-b827eb13a985"
  12s           12s             1       kubelet, jarvis-node2   spec.containers{test-pod}       Normal          Pulling                 pulling image "hypriot/
armhf-busybox:1.24"
  5s            5s              1       kubelet, jarvis-node2   spec.containers{test-pod}       Normal          Pulled                  Successfully pulled ima
ge "hypriot/armhf-busybox:1.24"
  4s            4s              1       kubelet, jarvis-node2   spec.containers{test-pod}       Normal          Created                 Created container
  4s            4s              1       kubelet, jarvis-node2   spec.containers{test-pod}       Normal          Started
----

Check on the NFS server, if some data are written.

=== Monitoring ===

A namespace *monitoring* is present for monitoring tools.
You could install

* https://prometheus.io/[Prometheus] :

----
$ kubectl apply -f k8s/prometheus/ --record
----

* https://prometheus.io/docs/alerting/alertmanager/[alertmanager]:

----
$ kubectl apply -f k8s/alertmanager/ --record
----

* and other tools like https://github.com/kubernetes/kube-state-metrics[kube state metrics],  https://github.com/prometheus/node_exporter[node exporter] :

----
$ kubectl apply -f k8s/kube-state-metrics/ --record
$ kubectl apply -f k8s/node-exporter/ --record
----


=== Metrics ===

For some metrics, you could also install the https://www.influxdata.com/[InfluxDB] database :

----
$ kubectl apply -f k8s/influxdb/ --record
----

You can use kubectl exec to access a shell in the InfluxDB container and run the InfluxDB CLI.
Ex: setup the Home Assistant database and user :

----
$ kubectl get pods -n metrics
NAME                        READY     STATUS    RESTARTS   AGE
influxdb-679777db78-pfqtx   1/1       Running   0          3m
$ kubectl -n metrics exec influxdb-679777db78-pfqtx -i -t -- bash -il
influx -version
InfluxDB shell version: 1.5.2
$ influx
Connected to http://localhost:8086 version 1.5.2
InfluxDB shell version: 1.5.2
> CREATE DATABASE homeassistant
> CREATE USER homeassistant WITH PASSWORD 'mypassword'
> GRANT ALL ON homeassistant TO homeassistant
> SHOW DATABASES
name: databases
name
_internal
homeassistant
----

=== DNS ===

[PiHole](https://pi-hole.net/) is used to block Internet advertisements :

----
$ kubectl apply -f k8s/pihole/ --record
----

You could see services  :

----
$ kubectl get svc -n tools -o wide -l app=pi-hole
NAME          TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)        AGE       SELECTOR
pi-hole-dns   LoadBalancer   10.96.242.120    192.168.1.228   53:31937/UDP   15h       app=pi-hole
pi-hole-ui    LoadBalancer   10.107.222.227   192.168.1.227   80:32039/TCP   15h       app=pi-hole
----

=== Grafana ===

[Grafana](https://grafana.com/) could be installed to display informations :

----
$ kubectl apply -f k8s/grafana/ --record
----

Check the service  :

----
$ kubectl get svc -n tools -o wide -l app=grafana
NAME      TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE       SELECTOR
grafana   LoadBalancer   10.108.27.97   192.168.1.225   80:30694/TCP   17h       app=grafana
----


=== Vault ===

[Vault](https://www.vaultproject.io/) could be deployed :

----
$ kubectl apply -f k8s/vault --record
----

Check the service  :

----
$ kubectl get svc -n security -o wide -l app=vault
NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE       SELECTOR
vault     LoadBalancer   10.99.137.176   192.168.1.229   80:31919/TCP   45m       app=vault
----

Download the Vault CLI from [Hashicorp project](https://www.vaultproject.io/downloads.html), and
export the following environment for Vault CLI environment:

----
$ export VAULT_ADDR='https://192.168.1.229'
$ export VAULT_SKIP_VERIFY="true"
----

Verify that the Vault server is accessible using the Vault CLI:

----
$ vault status
Error checking seal status: Error making API request.

URL: GET http://192.168.1.229/v1/sys/seal-status
Code: 400. Errors:

* server is not yet initialized
----

See [Initializing the Vault](https://www.vaultproject.io/intro/getting-started/deploy.html#initializing-the-vault) on how to initialize a Vault cluster.
Check the status :

----
$ vault status
Key             Value
---             -----
Seal Type       shamir
Sealed          false
Total Shares    5
Threshold       3
Version         0.10.1
Cluster Name    vault-cluster-81cc7d1e
Cluster ID      24f2af3d-f0e1-6b60-d5d1-89d2be0a9aec
HA Enabled      false
----

Then write secret :

----
$ vault write secret/foo value=bar
Success! Data written to: secret/foo

$ vault read secret/foo
Key                 Value
---                 -----
refresh_interval    768h
value               bar
----